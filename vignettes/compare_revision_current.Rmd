---
title: "Habitat Conservation Planning Handbook: Old vs. New"
author: "Jacob Malcom, Defenders of Wildlife"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Habitat Conservation Planning Handbook\: Old vs. New}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(hcphb)
library(stringdist)
library(viridis)

data("hcp_rev_sent")
data("hcp_cur_sent")
data("hcp_rev_all")
data("hcp_cur_all")

hcp_cur <- hcp_cur_sent
hcp_rev <- hcp_rev_sent
```

## Habitat Conservation Planning Handbook: Old vs. New

Habitat Conservation Plans (HCPs) are a conservation tool enabled by [section 10(a)(1)(B)](https://www.fws.gov/endangered/what-we-do/hcp-overview.html) of the [U.S. Endangered Species Act (ESA)](https://www.fws.gov/endangered/laws-policies/). In return for taking actions that will benefit ESA-listed species, non-federal entities with an HCP receive an [Incidental Take Permit (ITP)](https://www.fws.gov/endangered/esa-library/pdf/HCPBK1.PDF) that allows such species to be harmed. The U.S. Fish and Wildlife Service (Dept. of the Interior) and National Marine Fisheries Service (Dept. of Commerce) administer the HCP programs. In 1996, the Services finalized their Habitat Conservation Planning Handbook (Handbook), which is used to guide the development of HCPs. In June, 2016, the Services issued a notice in the _Federal Register_ that they were revising the Handbook and [released the draft](https://www.regulations.gov/contentStreamer?documentId=FWS-HQ-ES-2016-0004-0002&disposition=attachment&contentType=pdf) for public comment. At `r length(hcp_rev_all)` pages for the revision and `r length(hcp_cur_all)` pages in the original (current), trying to determine all of the proposed changes could be rather time-consuming. To aid in the review process, we undertook some basic analyses of the two documents. In the following sections we exclude the tables of contents and acronym lists from analysis, but otherwise, all text returned from `pdftools::pdf_text` was analyzed. The analyses in this vignette are available from the R package in which the vignette was written, available from [GitHub](https://github.com/jacob-ogre/hcphb).

### Summary

The Handbook revision (REV) has `r length(hcp_rev)` chapters or sections and the current (CUR) has `r length(hcp_cur)` chapters or sections. Using the sentence tokenizer in `openNLP`, we find that these result in `r length(unlist(hcp_rev))` sentences for REV and `r length(unlist(hcp_cur))` sentences for CUR. Given the volume of information, and lacking a 'Track Changes' version, we would like to have a way to find the most-similar sentences between the two documents.

### Sentence similarities

We use the `stringdist` package to identify the most similar sentences between the two documents. We like the default metric, 'optimal string alignment' or 'restricted Damerau-Levenshtein distance' because it is simple to understand: the distance is the sum of changes needed to align two strings A and B:

```{r}
A <- "This is a string."
B <- "This is another string."
C <- "This is a strung."
stringdist(A, B)
stringdist(A, C)
```

We tokenized the documents using `Maxent_Sent_Token_Annotator` from `openNLP`, which tends to perform very well, but not perfectly. Because `pdf_text` doesn't present empty lines, which are part of the pattern for identifying section headings, those headings are concatenated with the first sentence of the section. That is, the sentence extraction is close but not perfect; however, if the heading and text didn't change at all between versions then the result is still an edit distance of 0. But there are differences...lots and lots of differences. Consider the comparison of sentences in REV chapter 1 to the sentences of all the chapters in CUR:

```{r, cache=TRUE}
ch1_dists <- lapply(hcp_cur, FUN = stringdistmatrix, b = hcp_rev$ch1)
ch1_maxes <- lapply(hcp_cur, FUN = get_max_dist, hcp_rev$ch1)
ch1_ratio <- list()
for(i in names(ch1_dists)) {
  ch1_ratio[[i]] <- ch1_dists[[i]] / ch1_maxes[[i]]
}
revch1_allcur_mins <- lapply(ch1_ratio, FUN = get_min_dists)
mins_df <- list()
for(i in names(revch1_allcur_mins)) {
  mins_df[[i]] <- bind_rows(revch1_allcur_mins[[i]]) 
  mins_df[[i]]$cur_ch <- i
  n_reps <- lapply(revch1_allcur_mins[[i]], 
                   FUN = function(x) length(x$pos))
  sents <- seq(1:length(n_reps))
  n_sents <- list()
  for(j in 1:length(sents)) n_sents[[j]] <- rep(sents[j], n_reps[j])
  mins_df[[i]]$rev_sent <- unlist(n_sents)
}
mins_df <- bind_rows(mins_df)
mins_df$rev_ch <- rep("ch1", length(mins_df$pos))
plot(mins_df$val,
     xlab = "Match No. (REV sequential)",
     ylab = "Edit distance (osa)",
     main = "")
abline(h = 0.25, col = substr(viridis(3), 1, 7)[2])
# ggplot(data = mins_df, aes(x = rev_sent, y = val)) +
#   geom_point() +
#   facet_wrap(~cur_ch, ncol=5)
```



You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

