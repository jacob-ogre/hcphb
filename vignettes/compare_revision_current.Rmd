---
title: "Habitat Conservation Planning Handbook: Old vs. New"
author: "Jacob Malcom, Defenders of Wildlife"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    fig_caption: yes
    toc: true
    toc_depth: 3
    toc_float: true
vignette: >
  %\VignetteIndexEntry{Habitat Conservation Planning Handbook\: Old vs. New}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)

library(dplyr)
library(ggplot2)
library(ggthemes)
library(hcphb)
# library(Matrix)
# library(RCircos)
library(readr)
# library(readxl)
library(stringdist)
library(stringr)
library(viridis)

data("hcp_rev_sent")
data("hcp_cur_sent")
data("hcp_rev_all")
data("hcp_cur_all")

hcp_cur <- hcp_cur_sent
hcp_rev <- hcp_rev_sent
```

## Habitat Conservation Planning Handbook: Old vs. New

Habitat Conservation Plans (HCPs) are a conservation tool enabled by [section 10(a)(1)(B)](https://www.fws.gov/endangered/what-we-do/hcp-overview.html) of the [U.S. Endangered Species Act (ESA)](https://www.fws.gov/endangered/laws-policies/). In return for taking actions that will benefit ESA-listed species, non-federal entities with an HCP receive an [Incidental Take Permit (ITP)](https://www.fws.gov/endangered/esa-library/pdf/HCPBK1.PDF) that allows such species to be harmed. The U.S. Fish and Wildlife Service (Dept. of the Interior) and National Marine Fisheries Service (Dept. of Commerce) administer the HCP programs. In 1996, the Services finalized their Habitat Conservation Planning Handbook (Handbook), which is used to guide the development of HCPs. In June, 2016, the Services issued a notice in the _Federal Register_ that they were revising the Handbook and [released the draft](https://www.regulations.gov/contentStreamer?documentId=FWS-HQ-ES-2016-0004-0002&disposition=attachment&contentType=pdf) for public comment. At `r length(hcp_rev_all)` pages for the revision and `r length(hcp_cur_all)` pages in the original (current), trying to determine all of the proposed changes could be rather time-consuming. To aid in the review process, we undertook some basic analyses of the two documents. In the following sections we exclude the tables of contents and acronym lists from analysis, but otherwise, all text returned from `pdftools::pdf_text` was analyzed. The analyses in this vignette are available from the R package in which the vignette was written, available from [GitHub](https://github.com/jacob-ogre/hcphb).

### Summary of the documents

The Handbook revision (REV) has `r length(hcp_rev)` chapters or sections and the current (CUR) has `r length(hcp_cur)` chapters or sections. Using the sentence tokenizer in `openNLP`, we find that these result in `r length(unlist(hcp_rev))` sentences for REV and `r length(unlist(hcp_cur))` sentences for CUR. Given the volume of information, and lacking a 'Track Changes' version, we would like to have a way to find the most-similar sentences between the two documents.

### Sentence similarities: Chapter 1 only

We use the `stringdist` package to identify the most similar sentences between the two documents. We like the default metric, 'optimal string alignment' or 'restricted Damerau-Levenshtein distance' because it is simple to understand: the distance is the sum of changes needed to align two strings A and B:

```{r exampledist}
A <- "This is a string."
B <- "This is another string."
C <- "This is a strung."
stringdist(A, B)
stringdist(A, C)
```

We tokenized the documents using `Maxent_Sent_Token_Annotator` from `openNLP`, which tends to perform very well, but not perfectly. Because `pdf_text` doesn't preserve empty lines, which are part of the pattern for identifying section headings, those headings are concatenated with the first sentence of the section. That is, the sentence extraction is close but not perfect; however, if the heading and text didn't change at all between versions then the result is still an edit distance of 0. But there are differences...lots and lots of differences. Consider the comparison of sentences in REV chapter 1 to the sentences of all the chapters in CUR. First we gather the pairwise distances:

```{r ch1_dist, cache=TRUE}
ch1_dists <- lapply(hcp_cur, FUN = stringdistmatrix, b = hcp_rev$ch1)
ch1_maxes <- lapply(hcp_cur, FUN = get_max_dist, hcp_rev$ch1)
ch1_ratio <- calc_dist_ratio(ch1_dists, ch1_maxes)
mins_ls <- lapply(ch1_ratio, FUN = get_min_dists)
mins_df <- create_mins_df(mins_ls, "ch1")
knitr::kable(head(mins_df, 10))
```

And then we can plot the similarities of REV chapter 1 along the sentences of CUR:

```{r fig1, fig.cap="The distribution of similarities between sentences in chapter 1 of the revised HCP handbook and all the sentences in the current handbook. The yellow line is at the 0.01 percentile, the teal line at osa = 0.25, and purple at the 0.005 percentile."}
ggplot(data = mins_df, aes(x = rev_idx, y = val)) +
  geom_point(alpha = 0.2, size = 2) +
  labs(x = "Match index",
       y = "String distance (osa)") +
  geom_hline(yintercept = 0.25, color = substr(viridis(3), 1, 7)[2]) +
  geom_hline(yintercept = 0.218, color = substr(viridis(3), 1, 7)[1]) +
  geom_hline(yintercept = 0.3, color = substr(viridis(3), 1, 7)[3]) +
  theme_hc()
```

While osa = 0.25 seems like a reasonable cutoff (slightly less than the 0.01 percentile), we can examine a histogram of osa distances to see if that's reasonable:

```{r fig2, fig.cap="The distribution of string distances doesn't show a strong cutoff, but the bulk of (incorrect) matches starts somewhere above 0.3."}
qplot(mins_df$val, geom="histogram", bins = 40) + theme_hc()
```

For the time being, we'll use osa < 0.25 as the cutoff for "match" sentences.

### Matching sentences across all chapters

Because the test with chapter 1 appears to have worked, we can run all sentences in all REV chapters against all chapters and sentences in CUR:

```{r allbyall, cache=TRUE}
all_dists <- list()
for(i in names(hcp_rev)) {
  cur_dists <- lapply(hcp_cur, FUN = stringdistmatrix, b = hcp_rev[[i]])
  cur_maxes <- lapply(hcp_cur, FUN = get_max_dist, hcp_rev[[i]])
  cur_ratio <- calc_dist_ratio(cur_dists, cur_maxes)
  cur_min_ls <- lapply(cur_ratio, FUN = get_min_dists)
  cur_min_df <- create_mins_df(cur_min_ls, i)
  all_dists[[i]] <- cur_min_df
}
all_dists_df <- dplyr::bind_rows(all_dists)
save(all_dists_df, file = "../data-raw/all_dists_df.rda")
head(all_dists_df)
good_dists <- all_dists_df[all_dists_df$val <= 0.25, ]
cross_tab <- table(good_dists$rev_ch, good_dists$cur_ch)
knitr::kable(cross_tab)
```

We come up with `r sum(cross_tab)` matches (with an optimal string alignment ratio <= 0.25) for sentences between the REV and CUR Handbooks. Many of these are repeats, however; only `r comb <- paste(good_dists$cur_ch, good_dists$rev_sent, sep = ":"); length(unique(comb))` unique REV sentences match to CUR sentences.

```{r circos1, cache = TRUE}
all_dists_df$from <- str_c("current.", 
                           all_dists_df$cur_ch, ".", 
                           all_dists_df$cur_sent)
all_dists_df$to <- str_c("revised.", 
                         all_dists_df$rev_ch, ".", 
                         all_dists_df$rev_sent)

amat <- matrix(NA, nrow=length(unlist(hcp_cur)), ncol=length(unlist(hcp_rev)))
cur_chs <- names(hcp_cur)
cnames <- rep(NA, length(unlist(hcp_cur)))
st <- 1
for(i in cur_chs) {
  for(j in 1:length(hcp_cur[[i]])) {
    cnames[st] <- paste0("current.", i, ".", j)
    st <- st + 1
  }
}
rev_chs <- names(hcp_rev)
rnames <- rep(NA, length(unlist(hcp_rev)))
st <- 1
for(i in rev_chs) {
  for(j in 1:length(hcp_rev[[i]])) {
    rnames[st] <- paste0("revised.", i, ".", j)
    st <- st + 1
  }
}
row.names(amat) <- cnames
colnames(amat) <- rnames

for(i in 1:length(all_dists_df$cur_sent)) {
  amat[all_dists_df[i,]$from, all_dists_df[i,]$to] <- 1 - all_dists_df[i,]$val  
}

save(amat, file = "../data-raw/all_invdists_mat.rda")
edgebundleR::edgebundle(amat, cutoff = 0.75, width = 800)
# # Looks like I may have to do this in Circos and do a system call...
# # no idea if I can get that to show in Rmd..

```

What will show up?
